24年至今的笔记整理</br>
AI理论实践:</br>  
数据处理管道:</br>
&emsp;&emsp;自监督学习的方式，设计了自适应阈值动态伪标签机制，增强了数据信号。</br>
&emsp;&emsp;语音序列数据处理。对不同长度的语音特征，进行填充分段采样，使同批次内所有序列具有相同长度。</br>
&emsp;&emsp;机器翻译项目中，针对中英文文本数据集，进行语料库清洗与筛选和文本转换为子词序列，然后使用unigram算法在双语数据上联合训练，使之后的模型能够处理罕见词和未登录词。最后将分词后的文本转换为二进制格式，配置共享词典和多进程处理。</br>

模型架构设计：</br>
&emsp;&emsp;实现多层全连接网络+多种激活函数，引入ImprovedSequential优化网络。通过模块化设计支持不同网络架构的快速实验和对比。</br>

完整项目：</br>
&emsp;&emsp;AIAgent：构建了基于树形搜索的自主代码生成系统：设计三阶段迭代框架(draft→debug→improve)，通过智能策略平衡探索与利用；实现多进程安全沙箱执行环境，集成完整的异常捕获与超时控制；开发LLM驱动的代码生成与自修复管道，实现从任务理解到结果评估的全流程自动化；建立经验记忆系统持续优化代码质量，在机器学习任务中实现完全自主的解决方案开发。</br>
&emsp;&emsp;brief_RAG：构建了多智能体协同的搜索增强问答系统：设计三阶段专业化管道（问题精炼→关键词提取→知识增强回答），通过角色分工提升任务处理精度；实现异步网络检索引擎，集成HEAD预检查、编码检测和内容清洗，确保高质量实时知识获取；开发统一的LLM服务架构，支持GPU加速推理和健壮异常处理；建立端到端问答流水线，在复杂问题场景中实现准确高效的信息整合与回答生成。</br>
&emsp;&emsp;Fine-tuning:构建了特定样本的大模型微调系统：在云端Linux系统上高效微调Llama模型；设计自监督数据增强机制，基于特定风格自动生成高质量训练样本；开发字词敏感的提示工程，通过Few-shot示例和角色扮演引导模型掌握五言绝句创作规范；实现两阶段课程学习流水线，显著提升模型在指定风格任务完成度。</br>
&emsp;&emsp;&emsp;&emsp;构建了面向数学推理的大模型高效微调系统：在云端Linux系统上高效微调Llama模型；设计思维链增强的提示工程和动态n-shot示例选择；建立完整的训练优化流水线，集成梯度检查点、TF32加速和多进程数据加载；开发多任务评估框架，在GSM8K和AILuminate数据集上实现竞争力的数学问题求解精度。</br>


  

